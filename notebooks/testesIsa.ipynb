{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "df6c9d8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, SimpleRNN, Flatten, LSTM\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d1a004ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "from RainPredictionMachine.data import CleanDataRpm\n",
    "cleaner = CleanDataRpm()\n",
    "df = cleaner.clean_data(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "75017ffd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Chuva</th>\n",
       "      <th>Pres</th>\n",
       "      <th>Pres_max</th>\n",
       "      <th>Pres_min</th>\n",
       "      <th>Radiacao</th>\n",
       "      <th>Temp</th>\n",
       "      <th>Temp_orvalho</th>\n",
       "      <th>Temp_max</th>\n",
       "      <th>Temp_min</th>\n",
       "      <th>Temp_orvalho_max</th>\n",
       "      <th>...</th>\n",
       "      <th>Umid</th>\n",
       "      <th>Dir_vento</th>\n",
       "      <th>Rajada_vento</th>\n",
       "      <th>Vel_vento</th>\n",
       "      <th>Estaçao</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>Altitude</th>\n",
       "      <th>datahora</th>\n",
       "      <th>classe_chuva</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>957.9</td>\n",
       "      <td>957.9</td>\n",
       "      <td>957.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>21.7</td>\n",
       "      <td>21.7</td>\n",
       "      <td>23.7</td>\n",
       "      <td>21.7</td>\n",
       "      <td>23.7</td>\n",
       "      <td>...</td>\n",
       "      <td>100.0</td>\n",
       "      <td>130.5</td>\n",
       "      <td>3.75</td>\n",
       "      <td>2.10</td>\n",
       "      <td>TUPA</td>\n",
       "      <td>-21.927251</td>\n",
       "      <td>-50.490251</td>\n",
       "      <td>498.0</td>\n",
       "      <td>2021-01-01 00:00:00+00:00</td>\n",
       "      <td>nao chove</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>958.0</td>\n",
       "      <td>958.3</td>\n",
       "      <td>957.9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>21.4</td>\n",
       "      <td>21.4</td>\n",
       "      <td>21.7</td>\n",
       "      <td>21.4</td>\n",
       "      <td>21.6</td>\n",
       "      <td>...</td>\n",
       "      <td>100.0</td>\n",
       "      <td>109.0</td>\n",
       "      <td>5.40</td>\n",
       "      <td>3.35</td>\n",
       "      <td>TUPA</td>\n",
       "      <td>-21.927251</td>\n",
       "      <td>-50.490251</td>\n",
       "      <td>498.0</td>\n",
       "      <td>2021-01-01 01:00:00+00:00</td>\n",
       "      <td>nao chove</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>957.4</td>\n",
       "      <td>958.0</td>\n",
       "      <td>957.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>21.2</td>\n",
       "      <td>21.2</td>\n",
       "      <td>21.5</td>\n",
       "      <td>21.2</td>\n",
       "      <td>21.5</td>\n",
       "      <td>...</td>\n",
       "      <td>100.0</td>\n",
       "      <td>160.5</td>\n",
       "      <td>3.20</td>\n",
       "      <td>1.40</td>\n",
       "      <td>TUPA</td>\n",
       "      <td>-21.927251</td>\n",
       "      <td>-50.490251</td>\n",
       "      <td>498.0</td>\n",
       "      <td>2021-01-01 02:00:00+00:00</td>\n",
       "      <td>nao chove</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>956.6</td>\n",
       "      <td>957.4</td>\n",
       "      <td>956.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>21.3</td>\n",
       "      <td>20.9</td>\n",
       "      <td>21.3</td>\n",
       "      <td>...</td>\n",
       "      <td>100.0</td>\n",
       "      <td>160.5</td>\n",
       "      <td>3.20</td>\n",
       "      <td>1.40</td>\n",
       "      <td>TUPA</td>\n",
       "      <td>-21.927251</td>\n",
       "      <td>-50.490251</td>\n",
       "      <td>498.0</td>\n",
       "      <td>2021-01-01 03:00:00+00:00</td>\n",
       "      <td>nao chove</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>957.0</td>\n",
       "      <td>957.0</td>\n",
       "      <td>956.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>21.3</td>\n",
       "      <td>21.3</td>\n",
       "      <td>21.3</td>\n",
       "      <td>21.0</td>\n",
       "      <td>21.3</td>\n",
       "      <td>...</td>\n",
       "      <td>100.0</td>\n",
       "      <td>160.5</td>\n",
       "      <td>3.20</td>\n",
       "      <td>1.40</td>\n",
       "      <td>TUPA</td>\n",
       "      <td>-21.927251</td>\n",
       "      <td>-50.490251</td>\n",
       "      <td>498.0</td>\n",
       "      <td>2021-01-01 04:00:00+00:00</td>\n",
       "      <td>nao chove</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Chuva   Pres  Pres_max  Pres_min  Radiacao  Temp  Temp_orvalho  Temp_max  \\\n",
       "0    0.0  957.9     957.9     957.1       0.0  21.7          21.7      23.7   \n",
       "1    0.0  958.0     958.3     957.9       0.0  21.4          21.4      21.7   \n",
       "2    0.0  957.4     958.0     957.4       0.0  21.2          21.2      21.5   \n",
       "3    0.0  956.6     957.4     956.6       0.0  21.0          21.0      21.3   \n",
       "4    0.0  957.0     957.0     956.6       0.0  21.3          21.3      21.3   \n",
       "\n",
       "   Temp_min  Temp_orvalho_max  ...   Umid  Dir_vento  Rajada_vento  Vel_vento  \\\n",
       "0      21.7              23.7  ...  100.0      130.5          3.75       2.10   \n",
       "1      21.4              21.6  ...  100.0      109.0          5.40       3.35   \n",
       "2      21.2              21.5  ...  100.0      160.5          3.20       1.40   \n",
       "3      20.9              21.3  ...  100.0      160.5          3.20       1.40   \n",
       "4      21.0              21.3  ...  100.0      160.5          3.20       1.40   \n",
       "\n",
       "   Estaçao   Latitude  Longitude Altitude                  datahora  \\\n",
       "0     TUPA -21.927251 -50.490251    498.0 2021-01-01 00:00:00+00:00   \n",
       "1     TUPA -21.927251 -50.490251    498.0 2021-01-01 01:00:00+00:00   \n",
       "2     TUPA -21.927251 -50.490251    498.0 2021-01-01 02:00:00+00:00   \n",
       "3     TUPA -21.927251 -50.490251    498.0 2021-01-01 03:00:00+00:00   \n",
       "4     TUPA -21.927251 -50.490251    498.0 2021-01-01 04:00:00+00:00   \n",
       "\n",
       "   classe_chuva  \n",
       "0     nao chove  \n",
       "1     nao chove  \n",
       "2     nao chove  \n",
       "3     nao chove  \n",
       "4     nao chove  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "84001a81",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = df.set_index(['Estaçao', 'datahora'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "3aa25518",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "type object 'DataFrame' has no attribute 'as_matrix'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[0;32mIn [43]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m np\u001b[38;5;241m.\u001b[39marray(\u001b[38;5;28mlist\u001b[39m(df_test\u001b[38;5;241m.\u001b[39mgroupby(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEstaçao\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mapply(\u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDataFrame\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mas_matrix\u001b[49m)))\n",
      "\u001b[0;31mAttributeError\u001b[0m: type object 'DataFrame' has no attribute 'as_matrix'"
     ]
    }
   ],
   "source": [
    "np.array(list(df_test.groupby('Estaçao').apply(pd.DataFrame.as_matrix)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ee2462a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/isabelagaio/.pyenv/versions/3.8.12/envs/rain-prediction-machine/lib/python3.8/site-packages/sklearn/preprocessing/_label.py:115: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "from RainPredictionMachine.Trainer import pipe_creator\n",
    "full_pipe, X_train, y_train = pipe_creator(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "871dbb27",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/isabelagaio/.pyenv/versions/3.8.12/envs/rain-prediction-machine/lib/python3.8/site-packages/sklearn/preprocessing/_label.py:115: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('column_stransformer',\n",
       "                 ColumnTransformer(transformers=[('scaling ',\n",
       "                                                  Pipeline(steps=[('stdscaler',\n",
       "                                                                   StandardScaler())]),\n",
       "                                                  ['Pres', 'Pres_max',\n",
       "                                                   'Pres_min', 'Radiacao',\n",
       "                                                   'Temp', 'Temp_orvalho',\n",
       "                                                   'Temp_max', 'Temp_min',\n",
       "                                                   'Temp_orvalho_max',\n",
       "                                                   'Temp_orvalho_min',\n",
       "                                                   'Umid_max', 'Umid_min',\n",
       "                                                   'Umid', 'Rajada_vento',\n",
       "                                                   'Vel_vento', 'Dir_vento']),\n",
       "                                                 ('pass', 'passthrough',\n",
       "                                                  ['Latitude', 'Longitude',\n",
       "                                                   'Altitude'])]))])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "X = df.copy()\n",
    "y = pd.DataFrame(df['classe_chuva'])\n",
    "#----------------label encoder and to_categorical----------------\n",
    "label = LabelEncoder()\n",
    "y_enc = label.fit_transform(y)\n",
    "y_cat = to_categorical(y_enc)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y_cat, test_size=0.3) #separando train e test\n",
    "#----------------scaling pipeline----------------\n",
    "scaling_pipe = Pipeline([\n",
    "    ('stdscaler', StandardScaler()),\n",
    "])\n",
    "#----------------column transformer----------------\n",
    "#realizando as operações em paralelo\n",
    "col_trans = ColumnTransformer([\n",
    "    ('scaling ', scaling_pipe,[ 'Pres',\n",
    "                                'Pres_max',\n",
    "                                'Pres_min',\n",
    "                                'Radiacao',\n",
    "                                'Temp',\n",
    "                                'Temp_orvalho',\n",
    "                                'Temp_max',\n",
    "                                'Temp_min',\n",
    "                                'Temp_orvalho_max',\n",
    "                                'Temp_orvalho_min',\n",
    "                                'Umid_max',\n",
    "                                'Umid_min',\n",
    "                                'Umid',\n",
    "                                'Rajada_vento',\n",
    "                                'Vel_vento',\n",
    "                                'Dir_vento']), \n",
    "    ('pass', 'passthrough', ['Latitude','Longitude','Altitude'])])\n",
    "\n",
    "full_pipe = Pipeline([\n",
    "    ('column_stransformer', col_trans),\n",
    "#    (\"deep_learning\" , RNN_model ),\n",
    "])\n",
    "full_pipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5ad32bbe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6132, 23)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d9c1cb85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Chuva                           float64\n",
       "Pres                            float64\n",
       "Pres_max                        float64\n",
       "Pres_min                        float64\n",
       "Radiacao                        float64\n",
       "Temp                            float64\n",
       "Temp_orvalho                    float64\n",
       "Temp_max                        float64\n",
       "Temp_min                        float64\n",
       "Temp_orvalho_max                float64\n",
       "Temp_orvalho_min                float64\n",
       "Umid_max                        float64\n",
       "Umid_min                        float64\n",
       "Umid                            float64\n",
       "Dir_vento                       float64\n",
       "Rajada_vento                    float64\n",
       "Vel_vento                       float64\n",
       "Estaçao                          object\n",
       "Latitude                        float64\n",
       "Longitude                       float64\n",
       "Altitude                        float64\n",
       "datahora            datetime64[ns, UTC]\n",
       "classe_chuva                     object\n",
       "dtype: object"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c7fdfc06",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_t = full_pipe.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "80a41b37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6132, 19)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_t.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c4e039b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train_t1 = np.expand_dims(X_train_t, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "516d8671",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 6132, 19)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# X_train_t1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "806a2a72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6132, 4)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "939f2db6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "# X_pad = pad_sequences(X_train_t1)\n",
    "# X_pad = pad_sequences(X_train_t1, dtype= 'float32', padding= 'post', value=-1) \n",
    "# X_pad.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "fdcbf379",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_2 (LSTM)               (None, 20)                3520      \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 10)                210       \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 4)                 44        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3,774\n",
      "Trainable params: 3,774\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(LSTM(units=20, activation='tanh', input_shape=(6132, 23)))\n",
    "model.add(Dense(10, activation=\"tanh\"))\n",
    "model.add(Dense(4, activation=\"softmax\"))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "                  optimizer='rmsprop',\n",
    "                  metrics=['accurancy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8911c2e4",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Training data contains 1 samples, which is not sufficient to split it into a validation and training set as specified by `validation_split=0.2`. Either provide more data, or a different value for the `validation_split` argument.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [32]\u001b[0m, in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcallbacks\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m EarlyStopping\n\u001b[1;32m      2\u001b[0m es \u001b[38;5;241m=\u001b[39m EarlyStopping(patience\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m, restore_best_weights\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m----> 4\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train_t1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m32\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1000\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m         \u001b[49m\u001b[43mvalidation_split\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.2\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m          \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mes\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.8.12/envs/rain-prediction-machine/lib/python3.8/site-packages/keras/utils/traceback_utils.py:67\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[1;32m     66\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m---> 67\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[1;32m     68\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     69\u001b[0m   \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/.pyenv/versions/3.8.12/envs/rain-prediction-machine/lib/python3.8/site-packages/keras/engine/data_adapter.py:1496\u001b[0m, in \u001b[0;36mtrain_validation_split\u001b[0;34m(arrays, validation_split)\u001b[0m\n\u001b[1;32m   1493\u001b[0m split_at \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(math\u001b[38;5;241m.\u001b[39mfloor(batch_dim \u001b[38;5;241m*\u001b[39m (\u001b[38;5;241m1.\u001b[39m \u001b[38;5;241m-\u001b[39m validation_split)))\n\u001b[1;32m   1495\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m split_at \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m split_at \u001b[38;5;241m==\u001b[39m batch_dim:\n\u001b[0;32m-> 1496\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1497\u001b[0m       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTraining data contains \u001b[39m\u001b[38;5;132;01m{batch_dim}\u001b[39;00m\u001b[38;5;124m samples, which is not sufficient \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1498\u001b[0m       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mto split it into a validation and training set as specified by \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1499\u001b[0m       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`validation_split=\u001b[39m\u001b[38;5;132;01m{validation_split}\u001b[39;00m\u001b[38;5;124m`. Either provide more data, or a \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1500\u001b[0m       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdifferent value for the `validation_split` argument.\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m   1501\u001b[0m           batch_dim\u001b[38;5;241m=\u001b[39mbatch_dim, validation_split\u001b[38;5;241m=\u001b[39mvalidation_split))\n\u001b[1;32m   1503\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_split\u001b[39m(t, start, end):\n\u001b[1;32m   1504\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m t \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mValueError\u001b[0m: Training data contains 1 samples, which is not sufficient to split it into a validation and training set as specified by `validation_split=0.2`. Either provide more data, or a different value for the `validation_split` argument."
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "es = EarlyStopping(patience=5, restore_best_weights=True)\n",
    "\n",
    "model.fit(X_train_t1, y_train, batch_size=32, epochs=1000, verbose=1,\n",
    "         validation_split=0.2,\n",
    "          callbacks=[es])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66932dbf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
